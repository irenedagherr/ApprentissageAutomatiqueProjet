{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1652 entries, 0 to 1651\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Carbon concentration (weight%)                1652 non-null   float64\n",
      " 1   Silicon concentration (weight%)               1652 non-null   float64\n",
      " 2   Manganese concentration (weight%)             1652 non-null   float64\n",
      " 3   Sulphur concentration (weight%)               1652 non-null   float64\n",
      " 4   Phosphorus concentration (weight%)            1652 non-null   float64\n",
      " 5   Oxygen concentration (%)                      1652 non-null   float64\n",
      " 6   Nitrogen concentration (%)                    1652 non-null   float64\n",
      " 7   Current (A)                                   1652 non-null   float64\n",
      " 8   Voltage (V)                                   1652 non-null   float64\n",
      " 9   Heat input (kJ/mm)                            1652 non-null   float64\n",
      " 10  Interpass temperature (deg C)                 1652 non-null   float64\n",
      " 11  Post weld heat treatment temperature (deg C)  1652 non-null   float64\n",
      " 12  Post weld heat treatment time (hours)         1652 non-null   float64\n",
      " 13  Nickel concentration (weight%)                1652 non-null   float64\n",
      " 14  Chromium concentration (weight%)              1652 non-null   float64\n",
      " 15  Molybdenum concentration (weight%)            1652 non-null   float64\n",
      " 16  Vanadium concentration (weight%)              1652 non-null   float64\n",
      " 17  Copper concentration (weight%)                1652 non-null   float64\n",
      " 18  Titanium concentration (%)                    1652 non-null   float64\n",
      " 19  Aluminium concentration (%)                   1652 non-null   float64\n",
      " 20  Boron concentration (%)                       1652 non-null   float64\n",
      " 21  Niobium concentration (%)                     1652 non-null   float64\n",
      " 22  AC or DC                                      1652 non-null   float64\n",
      " 23  Electrode positive or negative                1652 non-null   float64\n",
      " 24  Type of weld                                  1652 non-null   float64\n",
      " 25  Yield strength (MPa)                          780 non-null    float64\n",
      " 26  Ultimate tensile strength (MPa)               738 non-null    float64\n",
      " 27  Elongation (%)                                700 non-null    float64\n",
      " 28  Reduction of Area (%)                         705 non-null    float64\n",
      " 29  Charpy temperature (deg C)                    877 non-null    float64\n",
      " 30  Charpy impact toughness (J)                   879 non-null    float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 400.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Convenience function to create display a progress bar.\n",
    "# Source : https://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console\n",
    "def print_progress_bar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "script_dir = Path.cwd() \n",
    "df = pd.read_csv(script_dir.parent / '4 - Dataset' / \"regression_weld_data.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 780 entries, 0 to 779\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Carbon concentration (weight%)                780 non-null    float64\n",
      " 1   Silicon concentration (weight%)               780 non-null    float64\n",
      " 2   Manganese concentration (weight%)             780 non-null    float64\n",
      " 3   Sulphur concentration (weight%)               780 non-null    float64\n",
      " 4   Phosphorus concentration (weight%)            780 non-null    float64\n",
      " 5   Oxygen concentration (%)                      780 non-null    float64\n",
      " 6   Nitrogen concentration (%)                    780 non-null    float64\n",
      " 7   Current (A)                                   780 non-null    float64\n",
      " 8   Voltage (V)                                   780 non-null    float64\n",
      " 9   Heat input (kJ/mm)                            780 non-null    float64\n",
      " 10  Interpass temperature (deg C)                 780 non-null    float64\n",
      " 11  Post weld heat treatment temperature (deg C)  780 non-null    float64\n",
      " 12  Post weld heat treatment time (hours)         780 non-null    float64\n",
      " 13  Nickel concentration (weight%)                780 non-null    float64\n",
      " 14  Chromium concentration (weight%)              780 non-null    float64\n",
      " 15  Molybdenum concentration (weight%)            780 non-null    float64\n",
      " 16  Vanadium concentration (weight%)              780 non-null    float64\n",
      " 17  Copper concentration (weight%)                780 non-null    float64\n",
      " 18  Titanium concentration (%)                    780 non-null    float64\n",
      " 19  Aluminium concentration (%)                   780 non-null    float64\n",
      " 20  Boron concentration (%)                       780 non-null    float64\n",
      " 21  Niobium concentration (%)                     780 non-null    float64\n",
      " 22  AC or DC                                      780 non-null    float64\n",
      " 23  Electrode positive or negative                780 non-null    float64\n",
      " 24  Type of weld                                  780 non-null    float64\n",
      " 25  Yield strength (MPa)                          780 non-null    float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 158.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_yieldStrength = df.iloc[:,:26]\n",
    "df_yieldStrength = df_yieldStrength.dropna()\n",
    "df_yieldStrength = df_yieldStrength.reset_index(drop=True) #Réinitialiser l'indexation\n",
    "#shuffle\n",
    "df_yieldStrength = df_yieldStrength.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(df_yieldStrength.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 780 entries, 0 to 779\n",
      "Data columns (total 1 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Yield strength (MPa)  780 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 6.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:25]\n",
    "ys = df.iloc[:,25:]\n",
    "print(ys.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainTest(X,y) :\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████----------------------------------------| 20.0% Complete\n",
      "\n",
      "Taille du dataset avec target Yield strength (MPa) : (780, 26)\n",
      "Résultat pour Yield strength (MPa) avec pour moyenne 508.55717948717944: \n",
      "               Model  RMSE_Train  RMSE_Test  R2_Train   R2_Test\n",
      "0     Bayesian Ridge   84.904131  79.159697  0.176272  0.229962\n",
      "1                SVR   82.999739  80.881945  0.212810  0.196090\n",
      "2  Gradient Boosting   54.248394  51.550607  0.663721  0.673433\n",
      "3      Random Forest   59.242829  50.788595  0.598951  0.683017\n",
      "4  Linear Regression   83.762880  77.457930  0.198268  0.262714\n",
      "5   Ridge Regression   79.944565  76.394933  0.269696  0.282812\n",
      "6   Lasso Regression   80.466548  76.703696  0.260128  0.277003\n",
      "Progress: |████████████████████------------------------------| 40.0% Complete\n",
      "\n",
      "Taille du dataset avec target Ultimate tensile strength (MPa) : (738, 26)\n",
      "Résultat pour Ultimate tensile strength (MPa) avec pour moyenne 594.3863143631436: \n",
      "               Model  RMSE_Train  RMSE_Test  R2_Train   R2_Test\n",
      "0     Bayesian Ridge   79.439885  76.296966  0.162923  0.334921\n",
      "1                SVR   71.915256  79.260133  0.313991  0.282258\n",
      "2  Gradient Boosting   47.586802  45.969479  0.699627  0.758566\n",
      "3      Random Forest   51.773551  49.870462  0.644447  0.715851\n",
      "4  Linear Regression   67.717928  85.694317  0.391732  0.160998\n",
      "5   Ridge Regression   68.218515  75.182986  0.382705  0.354200\n",
      "6   Lasso Regression   67.251689  81.313743  0.400079  0.244583\n",
      "Progress: |██████████████████████████████--------------------| 60.0% Complete\n",
      "\n",
      "Taille du dataset avec target Elongation (%) : (700, 26)\n",
      "Résultat pour Elongation (%) avec pour moyenne 26.275714285714287: \n",
      "               Model  RMSE_Train  RMSE_Test  R2_Train   R2_Test\n",
      "0     Bayesian Ridge    4.846635   4.804166  0.016986  0.022791\n",
      "1                SVR    3.676878   3.600213  0.434233  0.451208\n",
      "2  Gradient Boosting    3.128407   3.134256  0.590432  0.584070\n",
      "3      Random Forest    3.237450   2.902716  0.561383  0.643253\n",
      "4  Linear Regression    4.175043   4.655627  0.270541  0.082285\n",
      "5   Ridge Regression    4.175553   4.150591  0.270363  0.270590\n",
      "6   Lasso Regression    4.519368   4.456299  0.145259  0.159185\n",
      "Progress: |████████████████████████████████████████----------| 80.0% Complete\n",
      "\n",
      "Taille du dataset avec target Reduction of Area (%) : (705, 26)\n",
      "Résultat pour Reduction of Area (%) avec pour moyenne 71.79985815602836: \n",
      "               Model  RMSE_Train  RMSE_Test  R2_Train   R2_Test\n",
      "0     Bayesian Ridge    7.381938   6.823873  0.324939  0.387141\n",
      "1                SVR    5.738534   5.549735  0.592052  0.594637\n",
      "2  Gradient Boosting    5.559879   4.498924  0.617058  0.733611\n",
      "3      Random Forest    5.363513   5.061886  0.643630  0.662772\n",
      "4  Linear Regression    6.529611   5.729916  0.471826  0.567889\n",
      "5   Ridge Regression    6.393984   5.903345  0.493540  0.541335\n",
      "6   Lasso Regression    7.001967   6.404101  0.392645  0.460222\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "\n",
      "\n",
      "Taille du dataset avec target Charpy temperature (deg C) : (877, 26)\n",
      "Résultat pour Charpy temperature (deg C) avec pour moyenne -34.683010262257696: \n",
      "               Model  RMSE_Train  RMSE_Test  R2_Train   R2_Test\n",
      "0     Bayesian Ridge   31.464877  33.728099  0.128981  0.179799\n",
      "1                SVR   29.401824  33.296088  0.239457  0.200676\n",
      "2  Gradient Boosting   28.570393  31.431247  0.281862  0.287706\n",
      "3      Random Forest   28.306381  31.122036  0.295073  0.301651\n",
      "4  Linear Regression   29.572914  32.096448  0.230580  0.257237\n",
      "5   Ridge Regression   29.535394  32.008902  0.232531  0.261283\n",
      "6   Lasso Regression   29.508582  31.848047  0.233923  0.268689\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_predict, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fonction pour calculer le RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Configuration de la validation croisée (5 folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle Bayesian Ridge\n",
    "def bayesian_ridge_regression(X_train, X_test, y_train, y_test):\n",
    "    model = BayesianRidge()\n",
    "\n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Ajustement du modèle et prédictions sur l'ensemble de test\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"Bayesian Ridge\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle SVR avec Random Grid Search\n",
    "def svr_regression(X_train, X_test, y_train, y_test):\n",
    "    model = SVR()\n",
    "    param_grid = {\n",
    "        'kernel': ['rbf', 'poly'],\n",
    "        'C': np.logspace(-3, 3, 7),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'degree': [2, 3, 4]\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=4, cv=kf, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(best_model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"SVR\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle de Gradient Boosting avec Random Grid Search\n",
    "def gradient_boosting_regression(X_train, X_test, y_train, y_test):\n",
    "    model = GradientBoostingRegressor()\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.05],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=4, cv=kf, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(best_model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"Gradient Boosting\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle de Forêt Aléatoire avec Random Grid Search\n",
    "def random_forest_regression(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=4, cv=kf, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(best_model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"Random Forest\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction pour entraîner et évaluer la régression linéaire\n",
    "def linear_regression(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"Linear Regression\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction pour entraîner et évaluer la régression Ridge avec Random Grid Search\n",
    "def ridge_regression(X_train, X_test, y_train, y_test):\n",
    "    model = Ridge()\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=4, cv=kf, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(best_model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"Ridge Regression\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction pour entraîner et évaluer la régression Lasso avec Random Grid Search\n",
    "def lasso_regression(X_train, X_test, y_train, y_test):\n",
    "    model = Lasso()\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=4, cv=kf, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Validation croisée sur l'ensemble d'entraînement\n",
    "    y_train_pred_cv = cross_val_predict(best_model, X_train, y_train, cv=kf)\n",
    "\n",
    "    # Prédictions sur l'ensemble de test\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcul des scores\n",
    "    rmse_train = calculate_rmse(y_train, y_train_pred_cv)\n",
    "    rmse_test = calculate_rmse(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred_cv)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\"Model\": \"Lasso Regression\", \"RMSE_Train\": rmse_train, \"RMSE_Test\": rmse_test, \n",
    "            \"R2_Train\": r2_train, \"R2_Test\": r2_test}\n",
    "\n",
    "# Fonction principale qui exécute tous les modèles et retourne les résultats dans un DataFrame\n",
    "def evaluate_all_models(X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "\n",
    "    # Appel des fonctions de régression et stockage des résultats\n",
    "    results.append(bayesian_ridge_regression(X_train, X_test, y_train, y_test))\n",
    "    results.append(svr_regression(X_train, X_test, y_train, y_test))\n",
    "    results.append(gradient_boosting_regression(X_train, X_test, y_train, y_test))\n",
    "    results.append(random_forest_regression(X_train, X_test, y_train, y_test))\n",
    "    results.append(linear_regression(X_train, X_test, y_train, y_test))\n",
    "    results.append(ridge_regression(X_train, X_test, y_train, y_test))\n",
    "    results.append(lasso_regression(X_train, X_test, y_train, y_test))\n",
    "    # Conversion des résultats en DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def evaluateAllTarget(df, indexRangeFeatures , indexRangeTargets) :\n",
    "    progress = 0\n",
    "    # Display a progress bar\n",
    "    print_progress_bar(progress, int(len(indexRangeTargets)), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    for i in range (len(indexRangeTargets)) :\n",
    "        progress += 1\n",
    "        print_progress_bar(progress, int(len(indexRangeTargets)), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "        df_weld = df.iloc[:, indexRangeFeatures + [indexRangeTargets[i]] ]\n",
    "        df_weld = df_weld.dropna()\n",
    "        X = df_weld.iloc[:,indexRangeFeatures]\n",
    "        y = df_weld.iloc[:,len(indexRangeFeatures)]\n",
    "        col_name = df_weld.columns[len(indexRangeFeatures)]\n",
    "\n",
    "        print(f\"\\n\\nTaille du dataset avec target {col_name} : {df_weld.shape}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "        print(f\"Résultat pour {col_name} avec pour moyenne {y.mean()}: \")\n",
    "        df_results = evaluate_all_models(X_train, X_test, y_train, y_test)\n",
    "        print(df_results)\n",
    "\n",
    "#baye = bayesian_ridge_regression(X_train,  X_test, y_train, y_test)\n",
    "#svr = svr_regression(X_train,  X_test, y_train, y_test)\n",
    "#print(baye)\n",
    "#print(svr)\n",
    "\n",
    "evaluateAllTarget(df, list(range(25)), list(range(25,30)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
